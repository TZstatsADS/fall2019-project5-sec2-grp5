{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #shuffle test and train images\n",
    "# import random\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# path_img = '/Users/rong/Documents/Columbia_python_jupyter_notebook/fall2019-proj5-sec2--proj5-grp5/data/train_set/images/'\n",
    "\n",
    "# path_test_img = '/Users/rong/Documents/Columbia_python_jupyter_notebook/fall2019-proj5-sec2--proj5-grp5/data/train_set/test_images/'\n",
    "\n",
    "# images = os.listdir(path_img)\n",
    "# random.shuffle(images)\n",
    "# test_set = images[-len(images)//5:]\n",
    "# for image in test_set:\n",
    "\n",
    "#     shutil.move(os.path.join(path_img, image), os.path.join(path_test_img, image))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import os\n",
    "import fnmatch\n",
    "from math import hypot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset_path = fer_path\n",
    "# image_size=(48,48)\n",
    "\n",
    "# def load_fer2013():\n",
    "#     data = pd.read_csv(dataset_path)\n",
    "#     pixels = data['pixels'].tolist()\n",
    "#     width, height = 48, 48\n",
    "#     faces = []\n",
    "#     for pixel_sequence in pixels:\n",
    "#         face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "#         face = np.asarray(face).reshape(width, height)\n",
    "#         face = cv2.resize(face.astype('uint8'),image_size)\n",
    "#         faces.append(face.astype('float32'))\n",
    "#     faces = np.asarray(faces)\n",
    "#     faces = np.expand_dims(faces, -1)\n",
    "#     emotions = pd.get_dummies(data['emotion']).as_matrix()\n",
    "#     return faces, emotions\n",
    "\n",
    "# faces, emotions = load_fer2013()\n",
    "\n",
    "# xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fer2013_img(img_int,fer2013_path):\n",
    "    \"\"\"return an image of given index of img\n",
    "    Input\n",
    "    -----\n",
    "        fer2013_path:path of fer2013_file\n",
    "        img_int:int\"\"\"\n",
    "    \n",
    "    fer2013 = np.genfromtxt(fer2013_path, delimiter=',', dtype=None, encoding='utf8')\n",
    "    image = fer2013[img_int][1]\n",
    "    image_width, image_height =48, 48\n",
    "    result = np.fromstring(image, dtype=int, sep=\" \").reshape((image_height, image_width))\n",
    "    plt.imshow(result)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mac\n",
    "path_label = '/Users/rong/Documents/Columbia_python_jupyter_notebook/fall2019-proj5-sec2--proj5-grp5/data/train_set/label.csv'\n",
    "path_img = '/Users/rong/Documents/Columbia_python_jupyter_notebook/fall2019-proj5-sec2--proj5-grp5/data/train_set/images/'\n",
    "path_test_img = '/Users/rong/Documents/Columbia_python_jupyter_notebook/fall2019-proj5-sec2--proj5-grp5/data/train_set/test_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surface\n",
    "path_label = 'C:/Users/BurningBamboo/Desktop/fall2019-proj5-sec2--proj5-grp5/data/train_set/train_set/label.csv'\n",
    "path_img = 'C:/Users/BurningBamboo/Desktop/fall2019-proj5-sec2--proj5-grp5/data/train_set/train_set/images/'\n",
    "path_test_img = 'C:/Users/BurningBamboo/Desktop/fall2019-proj5-sec2--proj5-grp5/data/train_set/train_set/test_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fer2013\n",
    "fer_path = 'C:/Users/BurningBamboo/Desktop/fall2019-proj5-sec2--proj5-grp5/data/fer2013/fer2013.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv(path_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fer2013 = pd.read_csv(fer_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fer2013 = np.genfromtxt(fer_path, delimiter=',', dtype=None, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
